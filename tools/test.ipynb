{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import SimpleITK as sitk  # noqa: N813\n",
    "import numpy as np\n",
    "# import itk\n",
    "# import tempfile\n",
    "import monai\n",
    "# from monai.data import PILReader\n",
    "from monai.transforms import *\n",
    "# from monai.config import print_config\n",
    "from pathlib import Path\n",
    "from monai.networks.nets import SwinUNETR\n",
    "import torch\n",
    "from monai import transforms\n",
    "print(monai.__version__)\n",
    "torch.cuda.set_device(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"train/1/surface_volume/00.tif\",\n",
    "    \"train/1/surface_volume/01.tif\",\n",
    "    \"train/1/surface_volume/02.tif\",\n",
    "    \"train/1/surface_volume/03.tif\",\n",
    "    \"train/1/surface_volume/04.tif\",\n",
    "    \"train/1/surface_volume/05.tif\",\n",
    "    \"train/1/surface_volume/06.tif\",\n",
    "    \"train/1/surface_volume/07.tif\",\n",
    "    \"train/1/surface_volume/08.tif\",\n",
    "    \"train/1/surface_volume/09.tif\",\n",
    "    \"train/1/surface_volume/10.tif\",\n",
    "    \"train/1/surface_volume/11.tif\",\n",
    "    \"train/1/surface_volume/12.tif\",\n",
    "    \"train/1/surface_volume/13.tif\",\n",
    "    \"train/1/surface_volume/14.tif\",\n",
    "    \"train/1/surface_volume/15.tif\",\n",
    "    \"train/1/surface_volume/16.tif\",\n",
    "    \"train/1/surface_volume/17.tif\",\n",
    "    \"train/1/surface_volume/18.tif\",\n",
    "    \"train/1/surface_volume/19.tif\",\n",
    "    \"train/1/surface_volume/20.tif\",\n",
    "    \"train/1/surface_volume/21.tif\",\n",
    "    \"train/1/surface_volume/22.tif\",\n",
    "    \"train/1/surface_volume/23.tif\",\n",
    "    \"train/1/surface_volume/24.tif\",\n",
    "    \"train/1/surface_volume/25.tif\",\n",
    "    \"train/1/surface_volume/26.tif\",\n",
    "    \"train/1/surface_volume/27.tif\",\n",
    "    \"train/1/surface_volume/28.tif\",\n",
    "    \"train/1/surface_volume/29.tif\",\n",
    "    \"train/1/surface_volume/30.tif\",\n",
    "    \"train/1/surface_volume/31.tif\",\n",
    "    \"train/1/surface_volume/32.tif\",\n",
    "    \"train/1/surface_volume/33.tif\",\n",
    "    \"train/1/surface_volume/34.tif\",\n",
    "    \"train/1/surface_volume/35.tif\",\n",
    "    \"train/1/surface_volume/36.tif\",\n",
    "    \"train/1/surface_volume/37.tif\",\n",
    "    \"train/1/surface_volume/38.tif\",\n",
    "    \"train/1/surface_volume/39.tif\",\n",
    "    \"train/1/surface_volume/40.tif\",\n",
    "    \"train/1/surface_volume/41.tif\",\n",
    "    \"train/1/surface_volume/42.tif\",\n",
    "    \"train/1/surface_volume/43.tif\",\n",
    "    \"train/1/surface_volume/44.tif\",\n",
    "    \"train/1/surface_volume/45.tif\",\n",
    "    \"train/1/surface_volume/46.tif\",\n",
    "    \"train/1/surface_volume/47.tif\",\n",
    "    \"train/1/surface_volume/48.tif\",\n",
    "    \"train/1/surface_volume/49.tif\",\n",
    "    \"train/1/surface_volume/50.tif\",\n",
    "    \"train/1/surface_volume/51.tif\",\n",
    "    \"train/1/surface_volume/52.tif\",\n",
    "    \"train/1/surface_volume/53.tif\",\n",
    "    \"train/1/surface_volume/54.tif\",\n",
    "    \"train/1/surface_volume/55.tif\",\n",
    "    \"train/1/surface_volume/56.tif\",\n",
    "    \"train/1/surface_volume/57.tif\",\n",
    "    \"train/1/surface_volume/58.tif\",\n",
    "    \"train/1/surface_volume/59.tif\",\n",
    "    \"train/1/surface_volume/60.tif\",\n",
    "    \"train/1/surface_volume/61.tif\",\n",
    "    \"train/1/surface_volume/62.tif\",\n",
    "    \"train/1/surface_volume/63.tif\",\n",
    "    \"train/1/surface_volume/64.tif\"\n",
    "]\n",
    "ROOT = Path(r'/root/autodl-fs/vesuvius-challenge-ink-detection/')\n",
    "files = [ROOT / f for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.compose.Compose object at 0x7f76700f2370>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36m_apply_transform\u001b[0;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/monai/transforms/io/dictionary.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, reader)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \"\"\"\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_key_postfix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_key_postfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PosixPath' object is not iterable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36m_apply_transform\u001b[0;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/monai/transforms/compose.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_transform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0m_log_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"applying transform {transform}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7f76700f2190>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3516/2983950017.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0m_log_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"applying transform {transform}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: applying transform <monai.transforms.compose.Compose object at 0x7f76700f2370>"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\"], reader=\"PILReader\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "img = apply_transform(train_transform, files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms.transform import Transform\n",
    "class Copy(Transform):\n",
    "    def __init__(self, num_channel):\n",
    "        self.num_channel = num_channel\n",
    "\n",
    "    def __call__(self, data):\n",
    "        assert isinstance(data, torch.Tensor)\n",
    "        data = data.repeat(1, self.num_channel, 1, 1)  # output = (batch_size=1, num_channel, H, W)\n",
    "        return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6330, 8181)\n",
      "(1, 10, 6330, 8181)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "seg, _ = LoadImage(image_only=False, reader='PILReader')(ROOT / 'train' / '1'/ 'mask.png')\n",
    "seg = AddChannel()(seg)\n",
    "print(seg.size())\n",
    "seg = Copy(10)(seg)\n",
    "print(seg.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# print(\"Loading data...\")\n",
    "raw, meta = LoadImage(image_only=False, reader='PILReader')(files)\n",
    "seg, _ = LoadImage(image_only=False, reader='PILReader')(ROOT / 'train' / '1'/ 'mask.png')\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# print(f\"image data shape: {seg.shape}\")\n",
    "# raw = AddChannel()(raw)\n",
    "# seg = AddChannel()(seg)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# print(f\"image data shape: {seg.shape}\")\n",
    "# raw = Orientation(axcodes=\"RAS\")(raw)\n",
    "# seg = Orientation(axcodes=\"RAS\")(seg)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = Spacing(pixdim=(1.5, 1.5, 2.0), mode=\"bilinear\")(raw)\n",
    "# seg = Spacing(pixdim=(1.5, 1.5, 2.0), mode=\"bilinear\")(seg)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = ScaleIntensityRange(\n",
    "#     a_min=-175, a_max=175, b_min=0.0, b_max=1.0, clip=True\n",
    "# )(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = CropForeground( source_key=\"image\")(raw)\n",
    "# seg = CropForeground( source_key=\"image\")(seg)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandCropByPosNegLabel(\n",
    "#     label=None,\n",
    "#     spatial_size=(96, 96, 96),\n",
    "#     pos=1,\n",
    "#     neg=1,\n",
    "#     num_samples=4,\n",
    "#     image_threshold=0,\n",
    "# )(raw, label=seg)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandFlip( prob=0.2, spatial_axis=0)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandFlip( prob=0.2, spatial_axis=1)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandFlip( prob=0.2, spatial_axis=2)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandRotate90( prob=0.2, max_k=3)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandScaleIntensity(factors=0.1, prob=0.1)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandShiftIntensity(offsets=0.1, prob=0.1)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = ToTensor()(raw)\n",
    "# print(f\"{type(raw)}\")\n",
    "# raw = torch.Tensor(raw).cuda(0)\n",
    "# print(f\"{type(raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1529/938625363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 创建一个NumPy数组\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw' is not defined"
     ]
    }
   ],
   "source": [
    "raw.shape\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# 创建一个NumPy数组\n",
    "\n",
    "# 使用numpy.unique函数计算各个元素的出现次数\n",
    "unique_elements, counts = np.unique(raw, return_counts=True)\n",
    "plt.plot(unique_elements[1:len(unique_elements)-1], counts[1:len(unique_elements)-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_croped = raw[:,1000:1100,1000:1100]\n",
    "# data = torch.Tensor(raw_croped).view(1, raw_croped.shape[0], raw_croped.shape[1], raw_croped.shape[2]).cuda(0)\n",
    "\n",
    "# (batch_size, in_channel, H, W, D)\n",
    "data = torch.rand((1, 1, 64, 64, 64)).cuda(0)\n",
    "data.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinUNETR(\n",
       "  (swinViT): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(1, 12, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers1): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=12, out_features=36, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=12, out_features=48, bias=True)\n",
       "              (linear2): Linear(in_features=48, out_features=12, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=12, out_features=36, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=12, out_features=48, bias=True)\n",
       "              (linear2): Linear(in_features=48, out_features=12, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=96, out_features=24, bias=False)\n",
       "          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers2): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=24, out_features=72, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=24, out_features=96, bias=True)\n",
       "              (linear2): Linear(in_features=96, out_features=24, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=24, out_features=72, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=24, out_features=96, bias=True)\n",
       "              (linear2): Linear(in_features=96, out_features=24, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=192, out_features=48, bias=False)\n",
       "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers3): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
       "              (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
       "              (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=384, out_features=96, bias=False)\n",
       "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers4): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder1): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(1, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(1, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder2): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder3): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder4): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder10): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder5): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder4): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(96, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder3): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(48, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder2): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(24, 12, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(24, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(24, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder1): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(12, 12, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(24, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(24, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (out): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(12, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SwinUNETR(\n",
    "    img_size=(64, 64, 64),\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    feature_size=12,\n",
    "    use_checkpoint=True,\n",
    ").cuda(0)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1, 64, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of the inputs have requires_grad=True. Gradients will be None\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():\n",
    "    out = model(data)\n",
    "print(type(out))\n",
    "print(out.size())\n",
    "del out, data\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
