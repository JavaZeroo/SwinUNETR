{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import SimpleITK as sitk  # noqa: N813\n",
    "import numpy as np\n",
    "# import itk\n",
    "# import tempfile\n",
    "import monai\n",
    "# from monai.data import PILReader\n",
    "from monai.transforms import *\n",
    "# from monai.config import print_config\n",
    "from pathlib import Path\n",
    "from monai.networks.nets import SwinUNETR\n",
    "import torch\n",
    "print(monai.__version__)\n",
    "torch.cuda.set_device(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"train/1/surface_volume/00.tif\",\n",
    "    \"train/1/surface_volume/01.tif\",\n",
    "    \"train/1/surface_volume/02.tif\",\n",
    "    \"train/1/surface_volume/03.tif\",\n",
    "    \"train/1/surface_volume/04.tif\",\n",
    "    \"train/1/surface_volume/05.tif\",\n",
    "    \"train/1/surface_volume/06.tif\",\n",
    "    \"train/1/surface_volume/07.tif\",\n",
    "    \"train/1/surface_volume/08.tif\",\n",
    "    \"train/1/surface_volume/09.tif\",\n",
    "    \"train/1/surface_volume/10.tif\",\n",
    "    \"train/1/surface_volume/11.tif\",\n",
    "    \"train/1/surface_volume/12.tif\",\n",
    "    \"train/1/surface_volume/13.tif\",\n",
    "    \"train/1/surface_volume/14.tif\",\n",
    "    \"train/1/surface_volume/15.tif\",\n",
    "    \"train/1/surface_volume/16.tif\",\n",
    "    \"train/1/surface_volume/17.tif\",\n",
    "    \"train/1/surface_volume/18.tif\",\n",
    "    \"train/1/surface_volume/19.tif\",\n",
    "    \"train/1/surface_volume/20.tif\",\n",
    "    \"train/1/surface_volume/21.tif\",\n",
    "    \"train/1/surface_volume/22.tif\",\n",
    "    \"train/1/surface_volume/23.tif\",\n",
    "    \"train/1/surface_volume/24.tif\",\n",
    "    \"train/1/surface_volume/25.tif\",\n",
    "    \"train/1/surface_volume/26.tif\",\n",
    "    \"train/1/surface_volume/27.tif\",\n",
    "    \"train/1/surface_volume/28.tif\",\n",
    "    \"train/1/surface_volume/29.tif\",\n",
    "    \"train/1/surface_volume/30.tif\",\n",
    "    \"train/1/surface_volume/31.tif\",\n",
    "    \"train/1/surface_volume/32.tif\",\n",
    "    \"train/1/surface_volume/33.tif\",\n",
    "    \"train/1/surface_volume/34.tif\",\n",
    "    \"train/1/surface_volume/35.tif\",\n",
    "    \"train/1/surface_volume/36.tif\",\n",
    "    \"train/1/surface_volume/37.tif\",\n",
    "    \"train/1/surface_volume/38.tif\",\n",
    "    \"train/1/surface_volume/39.tif\",\n",
    "    \"train/1/surface_volume/40.tif\",\n",
    "    \"train/1/surface_volume/41.tif\",\n",
    "    \"train/1/surface_volume/42.tif\",\n",
    "    \"train/1/surface_volume/43.tif\",\n",
    "    \"train/1/surface_volume/44.tif\",\n",
    "    \"train/1/surface_volume/45.tif\",\n",
    "    \"train/1/surface_volume/46.tif\",\n",
    "    \"train/1/surface_volume/47.tif\",\n",
    "    \"train/1/surface_volume/48.tif\",\n",
    "    \"train/1/surface_volume/49.tif\",\n",
    "    \"train/1/surface_volume/50.tif\",\n",
    "    \"train/1/surface_volume/51.tif\",\n",
    "    \"train/1/surface_volume/52.tif\",\n",
    "    \"train/1/surface_volume/53.tif\",\n",
    "    \"train/1/surface_volume/54.tif\",\n",
    "    \"train/1/surface_volume/55.tif\",\n",
    "    \"train/1/surface_volume/56.tif\",\n",
    "    \"train/1/surface_volume/57.tif\",\n",
    "    \"train/1/surface_volume/58.tif\",\n",
    "    \"train/1/surface_volume/59.tif\",\n",
    "    \"train/1/surface_volume/60.tif\",\n",
    "    \"train/1/surface_volume/61.tif\",\n",
    "    \"train/1/surface_volume/62.tif\",\n",
    "    \"train/1/surface_volume/63.tif\",\n",
    "    \"train/1/surface_volume/64.tif\"\n",
    "]\n",
    "ROOT = Path(r'/root/autodl-tmp/vesuvius-challenge-ink-detection/')\n",
    "files = [ROOT / f for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms.transform import Transform\n",
    "class Copy(Transform):\n",
    "    def __init__(self, num_channel):\n",
    "        self.num_channel = num_channel\n",
    "\n",
    "    def __call__(self, data):\n",
    "        assert isinstance(data, torch.Tensor)\n",
    "        data = data.repeat(1, self.num_channel, 1, 1)  # output = (batch_size=1, num_channel, H, W)\n",
    "        return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6330, 8181])\n",
      "torch.Size([1, 10, 6330, 8181])\n"
     ]
    }
   ],
   "source": [
    "seg, _ = LoadImage(image_only=False, reader='PILReader')(ROOT / 'train' / '1'/ 'mask.png')\n",
    "seg = AddChannel()(seg)\n",
    "print(seg.size())\n",
    "seg = Copy(10)(seg)\n",
    "print(seg.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "buffer is not large enough",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4499/2763266066.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(\"Loading data...\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PILReader'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PILReader'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;34m'mask.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(f\"image data shape: {raw.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(f\"image data shape: {seg.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/monai/transforms/io/array.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, filename, reader)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mimg_array\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNdarrayOrTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_dst_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/monai/data/image_reader.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_meta_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMetaKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSPATIAL_SHAPE\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_spatial_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m             \u001b[0mimg_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m             header[MetaKeys.ORIGINAL_CHANNEL_DIM] = (\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mArrayData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_load_libtiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_libtiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACCESS_READ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                     self.im = Image.core.map_buffer(\n\u001b[0m\u001b[1;32m    201\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                     )\n",
      "\u001b[0;31mValueError\u001b[0m: buffer is not large enough"
     ]
    }
   ],
   "source": [
    "# print(\"Loading data...\")\n",
    "raw, meta = LoadImage(image_only=False, reader='PILReader')(files)\n",
    "seg, _ = LoadImage(image_only=False, reader='PILReader')(ROOT / 'train' / '1'/ 'mask.png')\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# print(f\"image data shape: {seg.shape}\")\n",
    "# raw = AddChannel()(raw)\n",
    "# seg = AddChannel()(seg)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# print(f\"image data shape: {seg.shape}\")\n",
    "# raw = Orientation(axcodes=\"RAS\")(raw)\n",
    "# seg = Orientation(axcodes=\"RAS\")(seg)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = Spacing(pixdim=(1.5, 1.5, 2.0), mode=\"bilinear\")(raw)\n",
    "# seg = Spacing(pixdim=(1.5, 1.5, 2.0), mode=\"bilinear\")(seg)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = ScaleIntensityRange(\n",
    "#     a_min=-175, a_max=175, b_min=0.0, b_max=1.0, clip=True\n",
    "# )(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = CropForeground( source_key=\"image\")(raw)\n",
    "# seg = CropForeground( source_key=\"image\")(seg)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandCropByPosNegLabel(\n",
    "#     label=None,\n",
    "#     spatial_size=(96, 96, 96),\n",
    "#     pos=1,\n",
    "#     neg=1,\n",
    "#     num_samples=4,\n",
    "#     image_threshold=0,\n",
    "# )(raw, label=seg)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandFlip( prob=0.2, spatial_axis=0)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandFlip( prob=0.2, spatial_axis=1)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandFlip( prob=0.2, spatial_axis=2)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandRotate90( prob=0.2, max_k=3)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandScaleIntensity(factors=0.1, prob=0.1)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = RandShiftIntensity(offsets=0.1, prob=0.1)(raw)\n",
    "# print(f\"image data shape: {raw.shape}\")\n",
    "# raw = ToTensor()(raw)\n",
    "# print(f\"{type(raw)}\")\n",
    "# raw = torch.Tensor(raw).cuda(0)\n",
    "# print(f\"{type(raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw.shape\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# 创建一个NumPy数组\n",
    "\n",
    "# 使用numpy.unique函数计算各个元素的出现次数\n",
    "unique_elements, counts = np.unique(raw, return_counts=True)\n",
    "plt.plot(unique_elements[1:len(unique_elements)-1], counts[1:len(unique_elements)-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_croped = raw[:,1000:1100,1000:1100]\n",
    "# data = torch.Tensor(raw_croped).view(1, raw_croped.shape[0], raw_croped.shape[1], raw_croped.shape[2]).cuda(0)\n",
    "\n",
    "# (batch_size, in_channel, H, W, D)\n",
    "data = torch.rand((1, 1, 64, 64, 64)).cuda(0)\n",
    "data.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinUNETR(\n",
       "  (swinViT): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(1, 12, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers1): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=12, out_features=36, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=12, out_features=48, bias=True)\n",
       "              (linear2): Linear(in_features=48, out_features=12, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=12, out_features=36, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=12, out_features=12, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=12, out_features=48, bias=True)\n",
       "              (linear2): Linear(in_features=48, out_features=12, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=96, out_features=24, bias=False)\n",
       "          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers2): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=24, out_features=72, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=24, out_features=96, bias=True)\n",
       "              (linear2): Linear(in_features=96, out_features=24, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=24, out_features=72, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=24, out_features=24, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=24, out_features=96, bias=True)\n",
       "              (linear2): Linear(in_features=96, out_features=24, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=192, out_features=48, bias=False)\n",
       "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers3): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
       "              (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
       "              (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=384, out_features=96, bias=False)\n",
       "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers4): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (fn): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder1): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(1, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(1, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder2): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder3): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder4): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder10): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder5): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder4): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(96, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder3): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(48, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder2): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(24, 12, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(24, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(24, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder1): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(12, 12, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(24, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(24, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (out): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(12, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SwinUNETR(\n",
    "    img_size=(64, 64, 64),\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    feature_size=12,\n",
    "    use_checkpoint=True,\n",
    ").cuda(0)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1, 64, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of the inputs have requires_grad=True. Gradients will be None\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():\n",
    "    out = model(data)\n",
    "print(type(out))\n",
    "print(out.size())\n",
    "del out, data\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
